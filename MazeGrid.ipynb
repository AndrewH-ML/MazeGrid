{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MazeGrid",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMn+2pjjFSqSTpj31jb3RyZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewH707/MazeGrid/blob/main/MazeGrid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKu9XqxUIKjv"
      },
      "source": [
        "import collections"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8RVdvfM2kZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c766fa-1c29-4135-aba6-9ef732431c1d"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 38.0 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZz7_vnXjouY"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "Actions = {\n",
        "    0: [-1, 0], # north\n",
        "    1: [1, 0], # south\n",
        "    2: [0, -1], # west\n",
        "    3: [0, 1] # east\n",
        "} \n",
        "\n",
        "##################\n",
        "# In this game, there are two fixed bombs and the agent randomly starts\n",
        "# at one of the four corners. There are four barriers blocking the entrance\n",
        "# to the desired terminal state(the chest). There are only two appropriate\n",
        "# paths to the chest. The two bombs are also terminal states. \n",
        "####################\n",
        "\n",
        "class MazeGrid():\n",
        "\n",
        "  def __init__(self, size):\n",
        "    # this function initializes the environment \n",
        "    self.size = size \n",
        "    self.hard_reset()\n",
        "    return\n",
        "\n",
        "  def hard_reset(self):\n",
        "    self.state_action_values = collections.defaultdict(float)\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self): # this function resets the grid to initial conditions\n",
        "    self.terminal  = False\n",
        "    self.current_state = self.corner()\n",
        "    return\n",
        "  \n",
        "  # randomly picks corner to start new game from\n",
        "  def corner(self):\n",
        "    row, column = np.random.choice([0, 8], 2)\n",
        "    corner = (row, column)\n",
        "    return corner\n",
        "\n",
        "  def collision(self, state):\n",
        "    # this function checks whether the given state is a collision with \n",
        "    # a barrier\n",
        "    # returns true for collision,  false for no collision\n",
        "    if state in [(4, 3), (5, 3), (6, 3), (7, 3), (7, 4), (1, 4), (1, 5), (2, 5), (3, 5), (4, 5)]:\n",
        "      return True\n",
        "    else: return False\n",
        "\n",
        "  def bomb(self, state):\n",
        "    # checks to see if the given state is on a bomb and returns true if it is\n",
        "    if state in [(3, 3), (5, 5)]:\n",
        "      return True\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "  def step(self, current_state, action, change_values = True): # this step function takes in an action and \n",
        "                                 # the current state as input. \n",
        "\n",
        "    # check to see if it's the winning grid cell \n",
        "    if (current_state == (4, 4)):\n",
        "      reward = 10\n",
        "      if (change_values == True):\n",
        "        self.terminal = True\n",
        "      return current_state, reward\n",
        "\n",
        "    # check for any bombs\n",
        "    if (self.bomb(current_state) == True):\n",
        "      reward = -10\n",
        "      if (change_values == True):\n",
        "        self.terminal = True\n",
        "      return current_state, reward\n",
        "\n",
        "    reward = -1 # on all non-terminal transitions \n",
        "    size = self.size - 1\n",
        "\n",
        "    s_prime = (current_state[0] + action[0], current_state[1] + action[1])\n",
        "   \n",
        "   # check out of bounds condition vertical\n",
        "    if s_prime[0] < 0 or s_prime[0] > size:\n",
        "      s_prime = current_state # return same state\n",
        "    # check out of bounds condition; horizontal\n",
        "    if s_prime[1] < 0 or s_prime[1] > size:\n",
        "      s_prime = current_state\n",
        "    # check for any collisions with barriers \n",
        "    if (self.collision(s_prime) == True):\n",
        "      s_prime = current_state\n",
        "      reward = -2\n",
        "\n",
        "    #no more remaning checks, return next state and reward\n",
        "    if (change_values == True):\n",
        "      self.current_state = s_prime\n",
        "    \n",
        "    return s_prime, reward \n",
        "\n",
        "  def best_action(self, state):\n",
        "    up = self.state_action_values[state, 0]\n",
        "    down = self.state_action_values[state, 1]\n",
        "    left = self.state_action_values[state, 2]\n",
        "    right = self.state_action_values[state, 3]\n",
        "    action_values  = [up, down, left, right]\n",
        "    a = np.random.choice(np.flatnonzero(action_values == np.max(action_values)))\n",
        "    return a # return index of the best Action\n",
        "\n",
        "  def e_greedy(self, epsilon, state):\n",
        "    greedy = (1 - epsilon) + (epsilon/len(Actions))\n",
        "    non_greedy = epsilon/len(Actions)\n",
        "    p = [greedy, non_greedy]\n",
        "    p = np.array(p)\n",
        "    p /= p.sum() #normalize probabilities so they sum to 1\n",
        "    choice = np.random.choice(['greedy', 'non-greedy'], p = p)  \n",
        "\n",
        "    if choice == 'greedy':\n",
        "      action_index = self.best_action(state)# return index of best action\n",
        "\n",
        "    else:\n",
        "\n",
        "      index_options = [0, 1, 2, 3]\n",
        "      index_options.remove(self.best_action(state))\n",
        "      action_index = np.random.choice(a = index_options) # a random choice from a list \n",
        "                                                # of non-optimal action indicies\n",
        "      \n",
        "    return action_index\n",
        "\n",
        "\n",
        "  def MC_episode(self, epsilon):\n",
        "    self.reset()\n",
        "    episode = []\n",
        "    current_state = self.current_state\n",
        "    while (self.terminal != True):\n",
        "      action_index = self.e_greedy(epsilon, current_state)\n",
        "      action = Actions[action_index]\n",
        "      next_state, reward = self.step(current_state, action)\n",
        "      episode.append((current_state, action_index, reward))\n",
        "      current_state = next_state\n",
        "    return episode\n",
        "\n",
        "  # Here, we implmenent an on-policy first-visit algorithm for \n",
        "  # Monte Carlo control\n",
        "\n",
        "  def on_policy_first_visit_MC(self, gamma = 0.1, epsilon = 0.1, episodes = 50):\n",
        "    self.hard_reset()\n",
        "    counts = collections.defaultdict(int)\n",
        "    returns = collections.defaultdict(float)\n",
        "    for i in range(episodes): # number of episodes\n",
        "      episode = self.MC_episode(epsilon)\n",
        "      G = 0 # initialize return\n",
        "      state_action_pairs = [(s, a) for (s, a, r) in episode]\n",
        "      for t, (state, action, reward) in enumerate(episode):\n",
        "        G = gamma*G + reward\n",
        "        # check if the pair already exists\n",
        "        if not (state, action) in state_action_pairs[0:t]:\n",
        "          returns[state, action] += G\n",
        "          counts[state, action] += 1\n",
        "          self.state_action_values[state, action] = returns[state, action]/counts[state, action]\n",
        "      if (i % 10 == 0):\n",
        "        print('Episode: ', i)\n",
        "        self.visualize(self.state_action_values)\n",
        "    return \n",
        "  def Q_learning(self, gamma, epsilon, alpha, episodes):\n",
        "    self.hard_reset()\n",
        "    for i in range(episodes):\n",
        "      self.reset()\n",
        "      state = self.current_state\n",
        "      while (self.terminal != True):\n",
        "        a = self.e_greedy(epsilon, state)\n",
        "        next_state, reward = self.step(state, Actions[a], change_values = True)\n",
        "        next_a = self.best_action(next_state)\n",
        "        next_s_a_value = self.state_action_values[next_state, next_a]\n",
        "        current_s_a_value = self.state_action_values[state, a]\n",
        "        self.state_action_values[state, a] = current_s_a_value + alpha*(reward + gamma*next_s_a_value - current_s_a_value)\n",
        "        state = next_state\n",
        "\n",
        "      if (i % 10 == 0):\n",
        "        print('Episode :', i)\n",
        "        self.visualize(self.state_action_values) # create plot\n",
        "    return\n",
        "\n",
        "  def visualize(self, dictionary):\n",
        "    size = self.size\n",
        "    z = np.zeros((size,size))\n",
        "    for key in dictionary:\n",
        "      state = (key[0][0], key[0][1])\n",
        "      value = dictionary[key]\n",
        "      if np.abs(value) > np.abs(z[state[0], state[1]]):\n",
        "        z[state[0], state[1]] = value\n",
        "    c = plt.imshow(z, cmap = 'hot', interpolation= 'nearest')\n",
        "    plt.colorbar(c)\n",
        "    plt.title('State Values')\n",
        "    plt.show()\n",
        "    return \n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v8tcs3xNGDyc",
        "outputId": "e55f01df-bbb0-4815-8183-7f76595ca153"
      },
      "source": [
        "Q = MazeGrid(9)\n",
        "Q.Q_learning(gamma = 1, epsilon=0.1, alpha = 0.01, episodes = 50)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode : 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Episode : 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Episode : 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Episode : 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Episode : 40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oLyl5Y7cEsVZ",
        "outputId": "f05db68c-a98e-43b1-bd78-e0ed9c4590da"
      },
      "source": [
        "#create an instance of the MazeGrid class and specify a 9 by 9 arrangement of the game\n",
        "MC = MazeGrid(9)\n",
        "MC.on_policy_first_visit_MC() #use an on-policy first visit monte carlo approach"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Episode:  10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATYAAAEICAYAAADVzNh0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYgElEQVR4nO3df7RdZX3n8ffHEFACJS1BEBIBFwwtuhScNMJArfxQA1JoO9iB1h+gawBHWpiylhVZSx077YwzVmQNVBqRGlt+6KBolgYCjlikAiWBqECgDSmWRASuEggRxZDP/LH3jYfL/bHPvWefc8/en9daZ91z9t5n7+9B/PI8+9nP85VtIiKa5CWDDiAioteS2CKicZLYIqJxktgionGS2CKicZLYIqJxkthi2iS9SdLGQccRMVYS2wBIOlrSdyQ9Jeknkv5R0m+W+86QdFsX5zpAkiXtNI04Xipps6Rjx9l3saTruj1nxGyQxNZnkn4F+Brwf4BfA/YD/hvw837HYvtnwBeAd42JcQ5wOrC83zFF9EISW//9OwDb19h+3vaztm+y/T1JvwFcDhwp6RlJmwEkvU3SPZKelvSIpI92nO/W8u/m8jtHlt95j6R1kp6UtErS/hPEsxz4j5J27dj2Vop/N26QdGZ5ni2SNkg6e6IfVrYcD+r4/DlJ/73j80mS1patxO9Iem3Hvj+TtKm8zoOSjpv6H2XE+JLY+u+fgeclLZd0gqRfHd1hex1wDnC77d1szy93baVoVc0H3ga8T9LvlvveWP6dX37ndkmnAB8Cfh/YC/g2cM14wdj+DvBoeeyodwJX294GPA6cBPwKcCZwsaTXd/ujJR0OXAmcDewJ/A2wQtIukg4BzgV+0/buFIn14W6vETEqia3PbD8NHA0Y+AzwhKQVkvae5Dvfsv1929ttf48iSf32JJc5B/gftteVyekvgcMmabV9nrI7WnaVT6Hshtr+uu2HXPgH4Cbgt7r5zaWzgL+xfWfZUl1O0f0+Ange2AU4VNJc2w/bfmga14gAktgGokw4Z9heCLwG2Bf41ETHS3qDpFskPSHpKYrEtWCSS+wPXFJ2+TYDPwFEcT9vPH8HHCNpX+BU4CHb95TXPkHSHeUgx2bgxCmuPVlMF4zGVJ5rEbCv7fXA+cBHgcclXVvGEjEtSWwDZvsB4HMUCQ6KltxYVwMrgEW296C4D6dJjn8EONv2/I7Xy8pu53gx/ICiu/oOim7ocgBJuwBfAj4B7F12jVd2XHusnwKd9+r2GRPTX4yJaVfb15QxXG37aIoEaODjE1wjYkpJbH0m6dclXSBpYfl5EcUI5B3lIY8BCyXt3PG13YGf2P6ZpCXAH3bsewLYDryqY9vlwIWSXl1eYw9Jb58itOUU97mOAq4qt+1M0UV8Atgm6QTgLZOcYy3wh5LmSFrKC7vLnwHOKVufkjSvHBTZXdIhko4tE+nPgGfL3xQxLUls/bcFeANwp6StFAntXuCCcv83gfuAH0kaKbf9F+BjkrYAHwa+OHoy2z8F/gL4x7KLd4Tt6ylaPNdKero8/wlTxPUlisdP/p/tR8tzbwH+pLzekxQJdcUk5zgP+B1gM/BHwFc64lwN/Gfg0vJc64Ezyt27AP8TGAF+BLwcuHCKeCMmpCw0GRFNkxZbRDROEltENE4SW0Q0ThJbRDRO1ytCVLFgrnzALnWcOSrr+5T6Hsu/P5N6+Ocw8gtP9DxhJUuXLvXIyMjUBwJr1qxZZXvpTK7XT7UktgN2gdWvnfq4qNGGQQcwQ6+a+pA2W/y9mZ9jZGSE1atXVzpW0nRmmwxMLYktIoaBgW2DDqIWSWwRrWWKiR7Nk8QW0VppsUVE4ySxRUTjJLFFROMksUVEIzUzsVWaeSBpaVlgY72kD9YdVET0w3aKJ7mrvIbLlC22shTbZcCbgY3AXZJW2L6/7uAiok7N7YpWabEtAdbb3mD7OeBaimIfETH0tlV8DZcq99j2o1ivftRGihVgX0DSWRSViHjlzmP3RsTs09wWW88GD2wvA5YBLN5NWZY3YtZrd2LbRFEmbdTCcltEDLXttHlK1V3AwZIOpEhop/HCKkkRMbRa2mKzvU3SucAqYA5wpe37ao8sImrW7q4otldSFMqNiMZoeWKLiCZKYouIxklii4jGyUKTEdE4abFFROMYeH7QQdQidUUjWmu0xTazuaKSDpG0tuP1tKTzxxzzJklPdRzz4Rp+0A5psQ1K3eXx3lrz+eu2qg/XSIk/etEVtf0gcBjsWA1oE3D9OId+2/ZJM75gBUlsEa1Vy5Sq44CHbP+g1yfuRrqiEa3VVVd0gaTVHa+zJjjpacA1E+w7UtJ3Jd0g6dU9/CEvkhZbRGt1NSo6YnvxZAdI2hk4GbhwnN13A/vbfkbSicBXgIO7CLYrabFFtFpPF5o8Abjb9mNjd9h+2vYz5fuVwFxJC2Yc/gTSYotorZ4/x3Y6E3RDJe0DPGbbkpZQNKp+3MuLd0pii2it3iU2SfMo6qKc3bHtHADblwOnAu+TtA14FjjNdm0L0iaxRbRW70ZFbW8F9hyz7fKO95cCl/bkYhUksUW0WjOnVE05eCDpSkmPS7q3HwFFRL/0ZubBbFRlVPRzwNKa44iIvmtuYquyNPitkg6oP5SI6K+s7hERjdTM1T16lthSMDli2LS7/F4lKZgcMWzSFY2IxmluYqvyuMc1wO3AIZI2Snpv/WFFRP3aPSp6ej8CiYhBGL6kVUW6ohGtlcGDiGic5t5jS2KLaK0ktohopCS2iGiUtNgionGS2KLX6q5pubLm859Y8/mjDzIqGhGNlEnwEdEoPa158DCwhSJTbhtbqk+SgEso2vo/Bc6wfXdPLj6OJLaI1ur5PbZjbI9MsO8EijqiBwNvAD5d/q1FEltEa/V18OAU4PNlZao7JM2X9Arbj9ZxsRRMjmi1ypPgF0ha3fE6a8yJDNwkac04+wD2Ax7p+Lyx3FaLtNgiWqurUdGRsffNxjja9iZJLwdulvSA7VtnHOI0pcUW0Vq9W7bI9qby7+PA9cCSMYdsAhZ1fF5YbqtFEltEm/n5aq9JSJonaffR98BbgLHlOlcA71LhCOCpuu6vQbqiEe22vSdn2Ru4vniig52Aq23fKOkc2FERfiXFox7rKR73OLMnV57AlIlN0iLg8xTBG1hm+5I6g4qIPjA9eT7X9gbgdeNsv7zjvYH3z/xq1VRpsW0DLrB9d9ncXCPpZtv31xxbRNTJwC8GHUQ9qiwN/ijwaPl+i6R1FMO0SWwRw6xHLbbZqKt7bGVF+MOBO8fZl7qiEcOmN/fYZp3Ko6KSdgO+BJxv++mx+20vs73Y9uK95vYyxIioxWiLrcpryFRqsUmaS5HUrrL95XpDioi+GcKkVUWVUVEBnwXW2f5k/SFFRF+YxnZFq7TYjgLeCXxf0tpy24ds172UYUTUycBzgw6iHlVGRW8D1IdYIqLfWtxii4gmyuMeEdFIabFFRKOkxRYRjZPEFhGN0+a5ohHRYGmxRS/Nu73e82/du97zRwO0/AHdiGiqtNgiolHSYouIxmnwlKoUc4los+0VX5OQtEjSLZLul3SfpPPGOeZNkp6StLZ8fbjHv+QF0mKLaKvePcdWtXzAt22f1JMrTiGJLaLNelPMZdaVD0hXNKKtRgcPZtgV7TRZ+QDgSEnflXSDpFfPIPIppcUW0WbVW2wLJK3u+LzM9rLOA6YoH3A3sL/tZySdCHwFOHh6QU+tygq6LwVuBXYpj7/O9kfqCigi+qS7KVUjthdPtHOq8gGdic72Skl/LWmB7ZHugq6mSovt58CxZaadC9wm6Qbbd9QRUET0SY8GD6qUD5C0D/CYbUtaQnEb7Mczv/r4qqyga+CZ8uPc8uW6AoqIPurNA7rjlg8AXgk7KsKfCrxP0jbgWeC0MrfUomqVqjnAGuAg4DLbqSsaMex61GKrUj7A9qXApTO/WjWVRkVtP2/7MGAhsETSa8Y5JnVFI4ZJg+uKdvW4h+3NwC3A0nrCiYi+GR08qPIaMlMmNkl7SZpfvn8Z8GbggboDi4g+6PFzbLNFlXtsrwCWl/fZXgJ80fbX6g0rImrX5qXBbX+P4kniiGiatia2iGiorMcWEY2UFltENEqqVEVE47R58CAiGiz32CKiUdJia5kN9V9i67tqvsDymtcpePekUwNjGCSxRUQjpSsaEY2SUdGIaJx0RSOikZLYIqJRMqUqIhopLbaIaJQGDx6kYHJEW/VwaXBJSyU9KGm9pA+Os38XSV8o999ZFlauTeXEJmmOpHskZZHJiKbowQq65SK0lwEnAIcCp0s6dMxh7wWetH0QcDHw8Z79hnF002I7D1hXVyAR0We9a7EtAdbb3mD7OeBa4JQxx5wCLC/fXwccV9YjrUWlxCZpIfA24Iq6AomIAaie2BZIWt3xOqvjLPsBj3R83lhuY7xjbG8DngL27PXPGVV18OBTwAeA3Sc6IHVFI4ZMd497jNheXF8wvVWlStVJwOO210x2XOqKRgwZA89VfE1uE7Co4/PCctu4x0jaCdgD+PFMwp9Mla7oUcDJkh6m6DsfK+nv6wooIvqoN+X37gIOlnSgpJ2B04AVY45ZAby7fH8q8E3btS1BM2Vis32h7YW2D6AI+Ju231FXQBHRJz0aPCjvmZ0LrKIYYPyi7fskfUzSyeVhnwX2lLQe+FPgRY+E9FIe0I1oqx5OqbK9Elg5ZtuHO97/DHh7b642ta4Sm+1vAd+qJZKI6L9MqYqIRsmyRRHROA2eK5rEFtFmabFFRKNkPbaIaKS02CKiUdJii6FTc93PeZ+v9fRsPbLe8we/nFLVQElsEW2WFltENEqeY4uIxklii4hGSlc0IholLbaIaJxMqYqIRkqLLSIape0P6JbLgm+hyO/bhqmoQ0RMIi02jrE9UlskEdFfGTyIiEbqQ1dU0v8GfodiAtdDwJm2N49z3MP0qGdYtRK8gZskrRlTKLUzqLNGi6k+0dCRlohGGR0VrfKamZuB19h+LfDPwIWTHHuM7cNmeruraovtaNubJL0cuFnSA7Zv7TzA9jJgGcDi3VRbWa2I6JE+dUVt39Tx8Q6K8nu1qtRis72p/Ps4cD2wpM6gIqJPqpffWzDaIytf4/bcKngPcMME+6bsGVY1ZYtN0jzgJba3lO/fAnxsJheNiFmgu8c9RibrHkr6BrDPOLsusv3V8piLgG3AVROcZsqeYVVVuqJ7A9dLGj3+ats3TudiETHL9Kgravv4yfZLOgM4CThuogrwnT1DSaM9w3oSm+0NwOumc/KImMX6NKVK0lLgA8Bv2/7pBMf0tGdYdVQ0Ihqo+i22GbkU2J2ie7lW0uUAkvaVNFo9fm/gNknfBf4J+PpMeoZ5ji2ipfr1fK7tgybY/kPgxPJ9T3uGSWwRLdbQqaJJbBFt1eAZVUlsEW2WFltENMp2Glt9L4mtsf6l3tOn7mczpMUWEY2Se2wR0UhJbBHRKA1eGTyJLaKtGlykKoktos3SFY2IRsngQUQ0Uu6xRUSjNLnFVmnZIknzJV0n6QFJ6yTl8cyIITea2PqwbFHfVW2xXQLcaPtUSTsDu9YYU0T0QatHRSXtAbwROAPA9nM0d4pZRKs09R5bla7ogcATwN9KukfSFeXSvS+QuqIRw6XJXdEqiW0n4PXAp20fDmwFPjj2INvLbC+2vXivuT2OMiJq0ebEthHYaPvO8vN1FIkuIobY6JSqKq+ZkPRRSZvKegdrJZ04wXFLJT0oab2kFzWeulGlStWPJD0i6RDbDwLHAffP5KIRMTv0sTV2se1PTLRT0hzgMuDNFI2puyStsD2tXFN1VPSPgavKEdENwJnTuVhEzB6zbFR0CbC+LOqCpGuBU5hmI6pSYrO9FpiwCnREDJ8uH9BdIGl1x+dltpd1cblzJb0LWA1cYPvJMfv3Ax7p+LwReEMX53+BzDyIaLEu7p+N2J6wcSPpG8A+4+y6CPg08OcUufTPgb8C3tNNnN1KYotoqV5OqbJ9fJXjJH0G+No4uzYBizo+Lyy3TUsqwUe0WD8e95D0io6PvwfcO85hdwEHSzqwvJd/GrBiutdMiy2ipfo4ePC/JB1WXvJh4GwASfsCV9g+0fY2SecCq4A5wJW275vuBZPYIlqqX6t72H7nBNt/CJzY8XklsLIX10xii2ixps4VTWKLaKkmr8eWxNZUB9d8/lU1n/9VNZ8/UqUqIpopLbaIaJRZNqWqp5LYIloq99giopGS2CKiUTJ4EBGNlBZbRDRKk1tsU06Cl3RIx5K+ayU9Len8fgQXEfUxRbm5Kq9hU2Vp8AeBw2DH8r2bgOtrjisi+qCpLbZuu6LHAQ/Z/kEdwURE/+Rxj186DbimjkAior+anNgqLzRZLv52MvB/J9ifgskRQ6Yf5fcGoZsW2wnA3bYfG29nWdhhGcDi3eQexBYRNcqUqsLppBsa0RhN7opWSmyS5lEUMj273nAiop9andhsbwX2rDmWiOijfj2gK+kLwCHlx/nAZtuHjXPcw8AWiny7bbJyf1PJzIOIFutTzYP/NPpe0l8BT01y+DG2R2Z6zSS2iJbq9z02SQL+ADi27mulrmhES42OilZ5AQtGH+cqX2dN45K/BTxm+18mCekmSWumef4d0mKLaLEu7rGNTHbPS9I3gH3G2XWR7a+W76d6suJo25skvRy4WdIDtm+tHuIvJbFFtFQvu6K2j59sv6SdgN8H/v0k59hU/n1c0vXAEmBaiS1d0YgWe77iqweOBx6wvXG8nZLmSdp99D3wFuDe6V4siS2ipUYf9+jTlKoXzTOXtK+k0crvewO3Sfou8E/A123fON2LpSs6nn7UtKy7LmfdUvezEfo1Kmr7jHG2/RA4sXy/AXhdr66XxBbRUtvJXNGIaKBWT6mKiOZpcs2DJLaIFkuLLSIapfXLFkVE82ShyYhopLTYIqJRmjx4UGnmgaT/Kuk+SfdKukbSS+sOLCLq18cpVX1VpRL8fsCfAIttvwaYQzE9IiKGWJ+nVPVV1a7oTsDLJP0C2BX4YX0hRUS/DGNrrIopE1u5PtIngH8DngVusn3T2OPKheHOAnjlzr0OMyJ6rcmjolW6or8KnAIcCOwLzJP0jrHH2V5me7HtxXvN7X2gEdFbo8+xtfIeG8U6Sv9q+wnbvwC+DPyHesOKiLo1ObFVucf2b8ARknal6IoeB6yuNaqI6IthHBiooso9tjslXQfcDWwD7gGW1R1YRNSr9VOqbH8E+EjNsUREn7W2xRYRzWTguUEHUZPUPIhoqX49oCvp7eXMpe2SFo/Zd6Gk9ZIelPTWCb5/oKQ7y+O+IGnKB8qS2CJarE+jovdSlN57QSk9SYdSzGJ6NbAU+GtJc8b5/seBi20fBDwJvHeqCyaxRbRUvx73sL3O9oPj7DoFuNb2z23/K7CeopboDpIEHAtcV25aDvzuVNdMYotosQHPFd0PeKTj88ZyW6c9gc22t01yzItk8CCipbqcUrVAUufzq8ts73jsS9I3gH3G+d5Ftr863Rinq5bEtmYrI7qdH3TxlQXASB2x9En74n+snkBmoG3/G+w/0wtuh1Vbi+tWMWJ76UQ7bR8/jRA2AYs6Pi8st3X6MTBf0k5lq228Y16klsRme69ujpe02vbiqY+cnRL/4A37bxhE/JMlqj5ZAVwt6ZMU89APpqgCv4NtS7oFOBW4Fng3MGULMPfYIqJWkn5P0kbgSODrklYB2L4P+CJwP3Aj8H7bz5ffWSlp3/IUfwb8qaT1FPfcPjvlNW33/pd0Kf+1Haxhjx+G/zcMe/yzzWxpsQ373NPEP3jD/huGPf5ZZVa02CIiemm2tNgiInomiS0iGmegiU3S0nLy63pJHxxkLNMhaZGkWyTdX07yPW/QMU2HpDmS7pH0tUHH0i1J8yVdJ+kBSeskHTnomLqR0pb1GFhiKye7XgacABwKnF5Oih0m24ALbB8KHAG8fwh/A8B5wLpBBzFNlwA32v514HUM0e9Iacv6DLLFtgRYb3uD7ecoHr47ZYDxdM32o7bvLt9vofg/1ZTz2GYTSQuBtwFXDDqWbknaA3gj5XNNtp+zvXmwUXVttLTlTqS0Zc8MMrFVmQA7NCQdABwO3DnYSLr2KeADDOdiqgcCTwB/W3alr5A0b9BBVWV7EzBa2vJR4KnxSltG9zJ40AOSdgO+BJxv++lBx1OVpJOAx22vGXQs07QT8Hrg07YPB7YCQ3Ovtmppy+jeIBNblQmws56kuRRJ7SrbXx50PF06CjhZ0sMUtwKOlfT3gw2pKxuBjbZHW8nXUSS6YZHSljUZZGK7Czi4XPZ3Z4qbpisGGE/XykXwPguss/3JQcfTLdsX2l5o+wCKf/7ftD00LQbbPwIekXRIuek4inmHw2JHacvy36XjGKLBj9lsYOux2d4m6VxgFcVo0JXlpNhhchTwTuD7ktaW2z5ke+UAY2qbPwauKv/juAE4c8DxVJbSlvXJlKqIaJwMHkRE4ySxRUTjJLFFROMksUVE4ySxRUTjJLFFROMksUVE4/x/1aI09ab9934AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Episode:  20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Episode:  30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Episode:  40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N1sBeVT6VOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce417a3-6e1c-4ff3-9ec2-5b04626a3745"
      },
      "source": [
        "test = MazeGrid(9)\n",
        "test.current_state"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SepF0OLzRLpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e34ed728-a298-4b8d-eec2-43b5c5d03b78"
      },
      "source": [
        "# set state so that the barrier is to the right , and bomb is just above\n",
        "\n",
        "# testing my step function with change_values = False and also testing \n",
        "# how I can through my state_values using s_prime from step\n",
        "test.current_state = (2, 3)\n",
        "test.state_action_values[3, 3] = 10\n",
        "print('terminal: ', test.terminal)\n",
        "up = test.step(test.current_state, action = Actions[1], change_values = False)[0]\n",
        "print(test.state_action_values[up], test.terminal)\n",
        "\n",
        "#test step into bomb\n",
        "print('Current State:' , test.current_state)\n",
        "print(' taking step South ...')\n",
        "next_state, reward = test.step(test.current_state, Actions[1])\n",
        "\n",
        "#also report current_state along with next_state to see if it's being updated correctly\n",
        "print('New State && Reward:' , test.current_state, next_state, reward) \n",
        "print('\\n')\n",
        "\n",
        "# go back to state (8, 3) and check step into barrier\n",
        "test.current_state = (8, 3)\n",
        "print('Current State:' , test.current_state)\n",
        "print(' taking step North ...')\n",
        "next_state, reward = test.step(test.current_state, Actions[0])\n",
        "print('New State && Reward:' , test.current_state, next_state, reward)\n",
        "\n",
        "print('\\n')\n",
        "# from state (3, 4), check what happens if step South and win\n",
        "test.current_state = (3, 4)\n",
        "print('Current State:' , test.current_state)\n",
        "print(' taking step South...')\n",
        "next_state, reward = test.step(test.current_state, Actions[1])\n",
        "print('New State && Reward:' , test.current_state, next_state, reward)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "terminal:  False\n",
            "10 False\n",
            "Current State: (2, 3)\n",
            " taking step South ...\n",
            "New State && Reward: (3, 3) (3, 3) -1\n",
            "\n",
            "\n",
            "Current State: (8, 3)\n",
            " taking step North ...\n",
            "New State && Reward: (8, 3) (8, 3) -2\n",
            "\n",
            "\n",
            "Current State: (3, 4)\n",
            " taking step South...\n",
            "New State && Reward: (4, 4) (4, 4) -1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMq7B6Ge_p3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71ee82ea-6caa-43a0-af79-ed4596d2d922"
      },
      "source": [
        "# lets check to see how our code runs in one episode when we start from a \n",
        "# random corner and continue taking steps until reaching terminal.\n",
        "# We check the trajectory with prints and do multiple episodes to see what outputs\n",
        "# end up coming up\n",
        "\n",
        "terminals = []\n",
        "for i in range(0, 100, 1): # episodes\n",
        "  print('Episode', i)\n",
        "  test.hard_reset()\n",
        "  terminal = test.terminal\n",
        "  print('Terminal? ... ', terminal)\n",
        "  print('\\n')\n",
        "  current_state = test.current_state\n",
        "  for j in range(0, 10000, 1):\n",
        "    if (terminal == True): \n",
        "      print('TERMINAL')\n",
        "      terminals.append(reward) # check the terminal states I'm getting\n",
        "      break;\n",
        "    print('STEP ', j)\n",
        "    #choose random action for now\n",
        "    a = np.random.randint(0, 4)\n",
        "    action = Actions[a]\n",
        "    print(\"Current State & Action\", current_state, action)\n",
        "    # step\n",
        "    print('Taking step with Action A...')\n",
        "    s_prime, reward = test.step(current_state, action)\n",
        "    print('New State & Reward: ', s_prime, reward)\n",
        "    print('\\n')\n",
        "    current_state = s_prime\n",
        "    terminal = test.terminal"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "STEP  241\n",
            "Current State & Action (6, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  242\n",
            "Current State & Action (6, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  243\n",
            "Current State & Action (5, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  244\n",
            "Current State & Action (6, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  245\n",
            "Current State & Action (6, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  246\n",
            "Current State & Action (7, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  247\n",
            "Current State & Action (6, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  248\n",
            "Current State & Action (5, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  249\n",
            "Current State & Action (5, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  250\n",
            "Current State & Action (5, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 6) -1\n",
            "\n",
            "\n",
            "STEP  251\n",
            "Current State & Action (5, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  252\n",
            "Current State & Action (6, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  253\n",
            "Current State & Action (7, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  254\n",
            "Current State & Action (6, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 6) -1\n",
            "\n",
            "\n",
            "STEP  255\n",
            "Current State & Action (5, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  256\n",
            "Current State & Action (6, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  257\n",
            "Current State & Action (6, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  258\n",
            "Current State & Action (6, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  259\n",
            "Current State & Action (7, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  260\n",
            "Current State & Action (8, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  261\n",
            "Current State & Action (8, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  262\n",
            "Current State & Action (8, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  263\n",
            "Current State & Action (8, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  264\n",
            "Current State & Action (8, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  265\n",
            "Current State & Action (8, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  266\n",
            "Current State & Action (8, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  267\n",
            "Current State & Action (7, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  268\n",
            "Current State & Action (7, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  269\n",
            "Current State & Action (7, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  270\n",
            "Current State & Action (7, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  271\n",
            "Current State & Action (7, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  272\n",
            "Current State & Action (7, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  273\n",
            "Current State & Action (8, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  274\n",
            "Current State & Action (8, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  275\n",
            "Current State & Action (7, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  276\n",
            "Current State & Action (8, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  277\n",
            "Current State & Action (8, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  278\n",
            "Current State & Action (7, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  279\n",
            "Current State & Action (6, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  280\n",
            "Current State & Action (5, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  281\n",
            "Current State & Action (6, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  282\n",
            "Current State & Action (6, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  283\n",
            "Current State & Action (7, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  284\n",
            "Current State & Action (6, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  285\n",
            "Current State & Action (5, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  286\n",
            "Current State & Action (5, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 8) -1\n",
            "\n",
            "\n",
            "STEP  287\n",
            "Current State & Action (4, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 8) -1\n",
            "\n",
            "\n",
            "STEP  288\n",
            "Current State & Action (3, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 8) -1\n",
            "\n",
            "\n",
            "STEP  289\n",
            "Current State & Action (3, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  290\n",
            "Current State & Action (2, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  291\n",
            "Current State & Action (2, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  292\n",
            "Current State & Action (2, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  293\n",
            "Current State & Action (2, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  294\n",
            "Current State & Action (2, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  295\n",
            "Current State & Action (1, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 7) -1\n",
            "\n",
            "\n",
            "STEP  296\n",
            "Current State & Action (1, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  297\n",
            "Current State & Action (1, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 7) -1\n",
            "\n",
            "\n",
            "STEP  298\n",
            "Current State & Action (1, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  299\n",
            "Current State & Action (1, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 7) -1\n",
            "\n",
            "\n",
            "STEP  300\n",
            "Current State & Action (1, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  301\n",
            "Current State & Action (2, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  302\n",
            "Current State & Action (2, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  303\n",
            "Current State & Action (1, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  304\n",
            "Current State & Action (2, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  305\n",
            "Current State & Action (1, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  306\n",
            "Current State & Action (1, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 7) -1\n",
            "\n",
            "\n",
            "STEP  307\n",
            "Current State & Action (1, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  308\n",
            "Current State & Action (1, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  309\n",
            "Current State & Action (1, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  310\n",
            "Current State & Action (0, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  311\n",
            "Current State & Action (0, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  312\n",
            "Current State & Action (0, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  313\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  314\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  315\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  316\n",
            "Current State & Action (0, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  317\n",
            "Current State & Action (0, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  318\n",
            "Current State & Action (0, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  319\n",
            "Current State & Action (0, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  320\n",
            "Current State & Action (0, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  321\n",
            "Current State & Action (0, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  322\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  323\n",
            "Current State & Action (0, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  324\n",
            "Current State & Action (0, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  325\n",
            "Current State & Action (0, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  326\n",
            "Current State & Action (0, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  327\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  328\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  329\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  330\n",
            "Current State & Action (0, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -1\n",
            "\n",
            "\n",
            "STEP  331\n",
            "Current State & Action (0, 4) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  332\n",
            "Current State & Action (0, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  333\n",
            "Current State & Action (0, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  334\n",
            "Current State & Action (1, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -1\n",
            "\n",
            "\n",
            "STEP  335\n",
            "Current State & Action (2, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -2\n",
            "\n",
            "\n",
            "STEP  336\n",
            "Current State & Action (2, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 6) -1\n",
            "\n",
            "\n",
            "STEP  337\n",
            "Current State & Action (3, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 7) -1\n",
            "\n",
            "\n",
            "STEP  338\n",
            "Current State & Action (3, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 7) -1\n",
            "\n",
            "\n",
            "STEP  339\n",
            "Current State & Action (4, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 7) -1\n",
            "\n",
            "\n",
            "STEP  340\n",
            "Current State & Action (3, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 8) -1\n",
            "\n",
            "\n",
            "STEP  341\n",
            "Current State & Action (3, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 7) -1\n",
            "\n",
            "\n",
            "STEP  342\n",
            "Current State & Action (3, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 8) -1\n",
            "\n",
            "\n",
            "STEP  343\n",
            "Current State & Action (3, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  344\n",
            "Current State & Action (2, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  345\n",
            "Current State & Action (2, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  346\n",
            "Current State & Action (2, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  347\n",
            "Current State & Action (2, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 7) -1\n",
            "\n",
            "\n",
            "STEP  348\n",
            "Current State & Action (3, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  349\n",
            "Current State & Action (2, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 7) -1\n",
            "\n",
            "\n",
            "STEP  350\n",
            "Current State & Action (3, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 7) -1\n",
            "\n",
            "\n",
            "STEP  351\n",
            "Current State & Action (4, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 8) -1\n",
            "\n",
            "\n",
            "STEP  352\n",
            "Current State & Action (4, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 7) -1\n",
            "\n",
            "\n",
            "STEP  353\n",
            "Current State & Action (4, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 6) -1\n",
            "\n",
            "\n",
            "STEP  354\n",
            "Current State & Action (4, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 6) -1\n",
            "\n",
            "\n",
            "STEP  355\n",
            "Current State & Action (5, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  356\n",
            "Current State & Action (5, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  357\n",
            "Current State & Action (5, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 8) -1\n",
            "\n",
            "\n",
            "STEP  358\n",
            "Current State & Action (4, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 8) -1\n",
            "\n",
            "\n",
            "STEP  359\n",
            "Current State & Action (4, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 8) -1\n",
            "\n",
            "\n",
            "STEP  360\n",
            "Current State & Action (3, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  361\n",
            "Current State & Action (2, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  362\n",
            "Current State & Action (1, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  363\n",
            "Current State & Action (0, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  364\n",
            "Current State & Action (1, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  365\n",
            "Current State & Action (2, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  366\n",
            "Current State & Action (2, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 7) -1\n",
            "\n",
            "\n",
            "STEP  367\n",
            "Current State & Action (3, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 7) -1\n",
            "\n",
            "\n",
            "STEP  368\n",
            "Current State & Action (4, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 7) -1\n",
            "\n",
            "\n",
            "STEP  369\n",
            "Current State & Action (3, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 7) -1\n",
            "\n",
            "\n",
            "STEP  370\n",
            "Current State & Action (4, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 8) -1\n",
            "\n",
            "\n",
            "STEP  371\n",
            "Current State & Action (4, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 7) -1\n",
            "\n",
            "\n",
            "STEP  372\n",
            "Current State & Action (4, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  373\n",
            "Current State & Action (5, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 6) -1\n",
            "\n",
            "\n",
            "STEP  374\n",
            "Current State & Action (5, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  375\n",
            "Current State & Action (6, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 6) -1\n",
            "\n",
            "\n",
            "STEP  376\n",
            "Current State & Action (5, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  377\n",
            "Current State & Action (5, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 7) -1\n",
            "\n",
            "\n",
            "STEP  378\n",
            "Current State & Action (4, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 8) -1\n",
            "\n",
            "\n",
            "STEP  379\n",
            "Current State & Action (4, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  380\n",
            "Current State & Action (5, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  381\n",
            "Current State & Action (6, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  382\n",
            "Current State & Action (5, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 8) -1\n",
            "\n",
            "\n",
            "STEP  383\n",
            "Current State & Action (4, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  384\n",
            "Current State & Action (5, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  385\n",
            "Current State & Action (6, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  386\n",
            "Current State & Action (5, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  387\n",
            "Current State & Action (6, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  388\n",
            "Current State & Action (6, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  389\n",
            "Current State & Action (7, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  390\n",
            "Current State & Action (8, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  391\n",
            "Current State & Action (8, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  392\n",
            "Current State & Action (8, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  393\n",
            "Current State & Action (8, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  394\n",
            "Current State & Action (8, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  395\n",
            "Current State & Action (8, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  396\n",
            "Current State & Action (8, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  397\n",
            "Current State & Action (8, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  398\n",
            "Current State & Action (8, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  399\n",
            "Current State & Action (8, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  400\n",
            "Current State & Action (8, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  401\n",
            "Current State & Action (7, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  402\n",
            "Current State & Action (8, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  403\n",
            "Current State & Action (8, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  404\n",
            "Current State & Action (8, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  405\n",
            "Current State & Action (7, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  406\n",
            "Current State & Action (7, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  407\n",
            "Current State & Action (8, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  408\n",
            "Current State & Action (7, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -1\n",
            "\n",
            "\n",
            "STEP  409\n",
            "Current State & Action (7, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -2\n",
            "\n",
            "\n",
            "STEP  410\n",
            "Current State & Action (7, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 5) -1\n",
            "\n",
            "\n",
            "STEP  411\n",
            "Current State & Action (6, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  412\n",
            "Current State & Action (6, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  413\n",
            "Current State & Action (7, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  414\n",
            "Current State & Action (7, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  415\n",
            "Current State & Action (7, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -1\n",
            "\n",
            "\n",
            "STEP  416\n",
            "Current State & Action (7, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  417\n",
            "Current State & Action (7, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  418\n",
            "Current State & Action (7, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  419\n",
            "Current State & Action (7, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  420\n",
            "Current State & Action (6, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  421\n",
            "Current State & Action (5, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  422\n",
            "Current State & Action (5, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  423\n",
            "Current State & Action (5, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  424\n",
            "Current State & Action (6, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  425\n",
            "Current State & Action (6, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  426\n",
            "Current State & Action (6, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  427\n",
            "Current State & Action (6, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  428\n",
            "Current State & Action (5, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  429\n",
            "Current State & Action (6, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  430\n",
            "Current State & Action (6, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 5) -1\n",
            "\n",
            "\n",
            "STEP  431\n",
            "Current State & Action (6, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  432\n",
            "Current State & Action (6, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  433\n",
            "Current State & Action (7, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  434\n",
            "Current State & Action (7, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  435\n",
            "Current State & Action (7, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  436\n",
            "Current State & Action (7, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  437\n",
            "Current State & Action (8, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  438\n",
            "Current State & Action (8, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  439\n",
            "Current State & Action (8, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  440\n",
            "Current State & Action (8, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  441\n",
            "Current State & Action (8, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  442\n",
            "Current State & Action (8, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  443\n",
            "Current State & Action (7, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  444\n",
            "Current State & Action (8, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  445\n",
            "Current State & Action (8, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  446\n",
            "Current State & Action (7, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  447\n",
            "Current State & Action (6, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  448\n",
            "Current State & Action (6, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  449\n",
            "Current State & Action (7, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  450\n",
            "Current State & Action (7, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  451\n",
            "Current State & Action (7, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  452\n",
            "Current State & Action (8, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  453\n",
            "Current State & Action (7, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  454\n",
            "Current State & Action (6, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  455\n",
            "Current State & Action (7, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  456\n",
            "Current State & Action (7, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  457\n",
            "Current State & Action (6, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  458\n",
            "Current State & Action (6, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 5) -1\n",
            "\n",
            "\n",
            "STEP  459\n",
            "Current State & Action (6, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 5) -1\n",
            "\n",
            "\n",
            "STEP  460\n",
            "Current State & Action (5, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 5) -10\n",
            "\n",
            "\n",
            "TERMINAL\n",
            "Episode 95\n",
            "Terminal? ...  False\n",
            "\n",
            "\n",
            "STEP  0\n",
            "Current State & Action (0, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  1\n",
            "Current State & Action (0, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  2\n",
            "Current State & Action (1, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 7) -1\n",
            "\n",
            "\n",
            "STEP  3\n",
            "Current State & Action (1, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  4\n",
            "Current State & Action (0, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  5\n",
            "Current State & Action (0, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  6\n",
            "Current State & Action (1, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 7) -1\n",
            "\n",
            "\n",
            "STEP  7\n",
            "Current State & Action (1, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  8\n",
            "Current State & Action (2, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -1\n",
            "\n",
            "\n",
            "STEP  9\n",
            "Current State & Action (2, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -2\n",
            "\n",
            "\n",
            "STEP  10\n",
            "Current State & Action (2, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -2\n",
            "\n",
            "\n",
            "STEP  11\n",
            "Current State & Action (2, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  12\n",
            "Current State & Action (2, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 7) -1\n",
            "\n",
            "\n",
            "STEP  13\n",
            "Current State & Action (1, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  14\n",
            "Current State & Action (1, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  15\n",
            "Current State & Action (1, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  16\n",
            "Current State & Action (0, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  17\n",
            "Current State & Action (0, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  18\n",
            "Current State & Action (0, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  19\n",
            "Current State & Action (0, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  20\n",
            "Current State & Action (0, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  21\n",
            "Current State & Action (1, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 7) -1\n",
            "\n",
            "\n",
            "STEP  22\n",
            "Current State & Action (1, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  23\n",
            "Current State & Action (1, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  24\n",
            "Current State & Action (2, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  25\n",
            "Current State & Action (1, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  26\n",
            "Current State & Action (1, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  27\n",
            "Current State & Action (0, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  28\n",
            "Current State & Action (0, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  29\n",
            "Current State & Action (0, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  30\n",
            "Current State & Action (0, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  31\n",
            "Current State & Action (0, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  32\n",
            "Current State & Action (1, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  33\n",
            "Current State & Action (1, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  34\n",
            "Current State & Action (1, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  35\n",
            "Current State & Action (2, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 8) -1\n",
            "\n",
            "\n",
            "STEP  36\n",
            "Current State & Action (3, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 7) -1\n",
            "\n",
            "\n",
            "STEP  37\n",
            "Current State & Action (3, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 7) -1\n",
            "\n",
            "\n",
            "STEP  38\n",
            "Current State & Action (4, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 8) -1\n",
            "\n",
            "\n",
            "STEP  39\n",
            "Current State & Action (4, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 7) -1\n",
            "\n",
            "\n",
            "STEP  40\n",
            "Current State & Action (4, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  41\n",
            "Current State & Action (5, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  42\n",
            "Current State & Action (5, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  43\n",
            "Current State & Action (5, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  44\n",
            "Current State & Action (6, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  45\n",
            "Current State & Action (5, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  46\n",
            "Current State & Action (6, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  47\n",
            "Current State & Action (6, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  48\n",
            "Current State & Action (5, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  49\n",
            "Current State & Action (6, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  50\n",
            "Current State & Action (6, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  51\n",
            "Current State & Action (6, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  52\n",
            "Current State & Action (5, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  53\n",
            "Current State & Action (5, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  54\n",
            "Current State & Action (5, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  55\n",
            "Current State & Action (5, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  56\n",
            "Current State & Action (6, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  57\n",
            "Current State & Action (5, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  58\n",
            "Current State & Action (5, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  59\n",
            "Current State & Action (5, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  60\n",
            "Current State & Action (5, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  61\n",
            "Current State & Action (5, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  62\n",
            "Current State & Action (6, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  63\n",
            "Current State & Action (5, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  64\n",
            "Current State & Action (5, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 8) -1\n",
            "\n",
            "\n",
            "STEP  65\n",
            "Current State & Action (5, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 8) -1\n",
            "\n",
            "\n",
            "STEP  66\n",
            "Current State & Action (6, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  67\n",
            "Current State & Action (7, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  68\n",
            "Current State & Action (7, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  69\n",
            "Current State & Action (8, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  70\n",
            "Current State & Action (8, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 5) -1\n",
            "\n",
            "\n",
            "STEP  71\n",
            "Current State & Action (8, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 4) -1\n",
            "\n",
            "\n",
            "STEP  72\n",
            "Current State & Action (8, 4) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 5) -1\n",
            "\n",
            "\n",
            "STEP  73\n",
            "Current State & Action (8, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  74\n",
            "Current State & Action (8, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  75\n",
            "Current State & Action (8, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  76\n",
            "Current State & Action (7, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -1\n",
            "\n",
            "\n",
            "STEP  77\n",
            "Current State & Action (7, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 5) -1\n",
            "\n",
            "\n",
            "STEP  78\n",
            "Current State & Action (8, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 5) -1\n",
            "\n",
            "\n",
            "STEP  79\n",
            "Current State & Action (8, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 5) -1\n",
            "\n",
            "\n",
            "STEP  80\n",
            "Current State & Action (8, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  81\n",
            "Current State & Action (8, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 5) -1\n",
            "\n",
            "\n",
            "STEP  82\n",
            "Current State & Action (8, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -1\n",
            "\n",
            "\n",
            "STEP  83\n",
            "Current State & Action (7, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 5) -1\n",
            "\n",
            "\n",
            "STEP  84\n",
            "Current State & Action (6, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -1\n",
            "\n",
            "\n",
            "STEP  85\n",
            "Current State & Action (7, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -2\n",
            "\n",
            "\n",
            "STEP  86\n",
            "Current State & Action (7, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -2\n",
            "\n",
            "\n",
            "STEP  87\n",
            "Current State & Action (7, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -2\n",
            "\n",
            "\n",
            "STEP  88\n",
            "Current State & Action (7, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  89\n",
            "Current State & Action (7, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -1\n",
            "\n",
            "\n",
            "STEP  90\n",
            "Current State & Action (7, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 5) -1\n",
            "\n",
            "\n",
            "STEP  91\n",
            "Current State & Action (8, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 5) -1\n",
            "\n",
            "\n",
            "STEP  92\n",
            "Current State & Action (8, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 4) -1\n",
            "\n",
            "\n",
            "STEP  93\n",
            "Current State & Action (8, 4) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 5) -1\n",
            "\n",
            "\n",
            "STEP  94\n",
            "Current State & Action (8, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  95\n",
            "Current State & Action (8, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  96\n",
            "Current State & Action (8, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  97\n",
            "Current State & Action (7, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  98\n",
            "Current State & Action (8, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  99\n",
            "Current State & Action (7, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  100\n",
            "Current State & Action (7, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  101\n",
            "Current State & Action (8, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  102\n",
            "Current State & Action (8, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  103\n",
            "Current State & Action (8, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  104\n",
            "Current State & Action (8, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  105\n",
            "Current State & Action (8, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  106\n",
            "Current State & Action (8, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  107\n",
            "Current State & Action (7, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  108\n",
            "Current State & Action (6, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  109\n",
            "Current State & Action (6, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  110\n",
            "Current State & Action (7, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  111\n",
            "Current State & Action (6, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  112\n",
            "Current State & Action (5, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 7) -1\n",
            "\n",
            "\n",
            "STEP  113\n",
            "Current State & Action (4, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  114\n",
            "Current State & Action (5, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 7) -1\n",
            "\n",
            "\n",
            "STEP  115\n",
            "Current State & Action (4, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 6) -1\n",
            "\n",
            "\n",
            "STEP  116\n",
            "Current State & Action (4, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 6) -1\n",
            "\n",
            "\n",
            "STEP  117\n",
            "Current State & Action (3, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 6) -2\n",
            "\n",
            "\n",
            "STEP  118\n",
            "Current State & Action (3, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 6) -2\n",
            "\n",
            "\n",
            "STEP  119\n",
            "Current State & Action (3, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 7) -1\n",
            "\n",
            "\n",
            "STEP  120\n",
            "Current State & Action (3, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 7) -1\n",
            "\n",
            "\n",
            "STEP  121\n",
            "Current State & Action (4, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  122\n",
            "Current State & Action (5, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 6) -1\n",
            "\n",
            "\n",
            "STEP  123\n",
            "Current State & Action (5, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 6) -1\n",
            "\n",
            "\n",
            "STEP  124\n",
            "Current State & Action (4, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 6) -2\n",
            "\n",
            "\n",
            "STEP  125\n",
            "Current State & Action (4, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 6) -1\n",
            "\n",
            "\n",
            "STEP  126\n",
            "Current State & Action (3, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 6) -1\n",
            "\n",
            "\n",
            "STEP  127\n",
            "Current State & Action (4, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 6) -2\n",
            "\n",
            "\n",
            "STEP  128\n",
            "Current State & Action (4, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 6) -2\n",
            "\n",
            "\n",
            "STEP  129\n",
            "Current State & Action (4, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 6) -1\n",
            "\n",
            "\n",
            "STEP  130\n",
            "Current State & Action (3, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -1\n",
            "\n",
            "\n",
            "STEP  131\n",
            "Current State & Action (2, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -2\n",
            "\n",
            "\n",
            "STEP  132\n",
            "Current State & Action (2, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -2\n",
            "\n",
            "\n",
            "STEP  133\n",
            "Current State & Action (2, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  134\n",
            "Current State & Action (1, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  135\n",
            "Current State & Action (0, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  136\n",
            "Current State & Action (0, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  137\n",
            "Current State & Action (0, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  138\n",
            "Current State & Action (0, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  139\n",
            "Current State & Action (0, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  140\n",
            "Current State & Action (0, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  141\n",
            "Current State & Action (0, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  142\n",
            "Current State & Action (0, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  143\n",
            "Current State & Action (0, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  144\n",
            "Current State & Action (0, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  145\n",
            "Current State & Action (0, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  146\n",
            "Current State & Action (1, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  147\n",
            "Current State & Action (2, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 8) -1\n",
            "\n",
            "\n",
            "STEP  148\n",
            "Current State & Action (3, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 7) -1\n",
            "\n",
            "\n",
            "STEP  149\n",
            "Current State & Action (3, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  150\n",
            "Current State & Action (2, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 7) -1\n",
            "\n",
            "\n",
            "STEP  151\n",
            "Current State & Action (1, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  152\n",
            "Current State & Action (1, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 7) -1\n",
            "\n",
            "\n",
            "STEP  153\n",
            "Current State & Action (1, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  154\n",
            "Current State & Action (0, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  155\n",
            "Current State & Action (0, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  156\n",
            "Current State & Action (1, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 7) -1\n",
            "\n",
            "\n",
            "STEP  157\n",
            "Current State & Action (1, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  158\n",
            "Current State & Action (1, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  159\n",
            "Current State & Action (2, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  160\n",
            "Current State & Action (2, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  161\n",
            "Current State & Action (2, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  162\n",
            "Current State & Action (2, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  163\n",
            "Current State & Action (1, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  164\n",
            "Current State & Action (1, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  165\n",
            "Current State & Action (1, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  166\n",
            "Current State & Action (0, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  167\n",
            "Current State & Action (1, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  168\n",
            "Current State & Action (0, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  169\n",
            "Current State & Action (0, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  170\n",
            "Current State & Action (0, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  171\n",
            "Current State & Action (0, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  172\n",
            "Current State & Action (0, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  173\n",
            "Current State & Action (0, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  174\n",
            "Current State & Action (0, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  175\n",
            "Current State & Action (1, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  176\n",
            "Current State & Action (0, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  177\n",
            "Current State & Action (0, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  178\n",
            "Current State & Action (0, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  179\n",
            "Current State & Action (0, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  180\n",
            "Current State & Action (0, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  181\n",
            "Current State & Action (0, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  182\n",
            "Current State & Action (1, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  183\n",
            "Current State & Action (2, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  184\n",
            "Current State & Action (2, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 8) -1\n",
            "\n",
            "\n",
            "STEP  185\n",
            "Current State & Action (3, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 8) -1\n",
            "\n",
            "\n",
            "STEP  186\n",
            "Current State & Action (3, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 8) -1\n",
            "\n",
            "\n",
            "STEP  187\n",
            "Current State & Action (3, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 7) -1\n",
            "\n",
            "\n",
            "STEP  188\n",
            "Current State & Action (3, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 8) -1\n",
            "\n",
            "\n",
            "STEP  189\n",
            "Current State & Action (3, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 7) -1\n",
            "\n",
            "\n",
            "STEP  190\n",
            "Current State & Action (3, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  191\n",
            "Current State & Action (2, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -1\n",
            "\n",
            "\n",
            "STEP  192\n",
            "Current State & Action (2, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  193\n",
            "Current State & Action (2, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  194\n",
            "Current State & Action (2, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  195\n",
            "Current State & Action (1, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  196\n",
            "Current State & Action (0, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  197\n",
            "Current State & Action (0, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  198\n",
            "Current State & Action (0, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  199\n",
            "Current State & Action (0, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  200\n",
            "Current State & Action (0, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  201\n",
            "Current State & Action (1, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -2\n",
            "\n",
            "\n",
            "STEP  202\n",
            "Current State & Action (1, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -2\n",
            "\n",
            "\n",
            "STEP  203\n",
            "Current State & Action (1, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  204\n",
            "Current State & Action (0, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  205\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  206\n",
            "Current State & Action (0, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  207\n",
            "Current State & Action (0, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  208\n",
            "Current State & Action (0, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  209\n",
            "Current State & Action (0, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  210\n",
            "Current State & Action (0, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  211\n",
            "Current State & Action (0, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  212\n",
            "Current State & Action (0, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  213\n",
            "Current State & Action (0, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  214\n",
            "Current State & Action (0, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  215\n",
            "Current State & Action (0, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  216\n",
            "Current State & Action (0, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  217\n",
            "Current State & Action (0, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  218\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  219\n",
            "Current State & Action (0, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -1\n",
            "\n",
            "\n",
            "STEP  220\n",
            "Current State & Action (0, 4) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -2\n",
            "\n",
            "\n",
            "STEP  221\n",
            "Current State & Action (0, 4) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -1\n",
            "\n",
            "\n",
            "STEP  222\n",
            "Current State & Action (0, 4) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -1\n",
            "\n",
            "\n",
            "STEP  223\n",
            "Current State & Action (0, 4) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -1\n",
            "\n",
            "\n",
            "STEP  224\n",
            "Current State & Action (0, 4) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -2\n",
            "\n",
            "\n",
            "STEP  225\n",
            "Current State & Action (0, 4) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  226\n",
            "Current State & Action (0, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -1\n",
            "\n",
            "\n",
            "STEP  227\n",
            "Current State & Action (0, 4) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -1\n",
            "\n",
            "\n",
            "STEP  228\n",
            "Current State & Action (0, 4) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  229\n",
            "Current State & Action (0, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  230\n",
            "Current State & Action (0, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  231\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  232\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  233\n",
            "Current State & Action (0, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  234\n",
            "Current State & Action (0, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  235\n",
            "Current State & Action (1, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -1\n",
            "\n",
            "\n",
            "STEP  236\n",
            "Current State & Action (2, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 6) -1\n",
            "\n",
            "\n",
            "STEP  237\n",
            "Current State & Action (3, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 6) -1\n",
            "\n",
            "\n",
            "STEP  238\n",
            "Current State & Action (4, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 6) -1\n",
            "\n",
            "\n",
            "STEP  239\n",
            "Current State & Action (3, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -1\n",
            "\n",
            "\n",
            "STEP  240\n",
            "Current State & Action (2, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  241\n",
            "Current State & Action (2, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -1\n",
            "\n",
            "\n",
            "STEP  242\n",
            "Current State & Action (2, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  243\n",
            "Current State & Action (1, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  244\n",
            "Current State & Action (0, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  245\n",
            "Current State & Action (1, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 7) -1\n",
            "\n",
            "\n",
            "STEP  246\n",
            "Current State & Action (1, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  247\n",
            "Current State & Action (2, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  248\n",
            "Current State & Action (2, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  249\n",
            "Current State & Action (2, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  250\n",
            "Current State & Action (2, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  251\n",
            "Current State & Action (2, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  252\n",
            "Current State & Action (2, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 8) -1\n",
            "\n",
            "\n",
            "STEP  253\n",
            "Current State & Action (3, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  254\n",
            "Current State & Action (2, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  255\n",
            "Current State & Action (1, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 8) -1\n",
            "\n",
            "\n",
            "STEP  256\n",
            "Current State & Action (2, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 8) -1\n",
            "\n",
            "\n",
            "STEP  257\n",
            "Current State & Action (1, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  258\n",
            "Current State & Action (0, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  259\n",
            "Current State & Action (0, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  260\n",
            "Current State & Action (0, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  261\n",
            "Current State & Action (0, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  262\n",
            "Current State & Action (0, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  263\n",
            "Current State & Action (0, 8) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 8) -1\n",
            "\n",
            "\n",
            "STEP  264\n",
            "Current State & Action (0, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  265\n",
            "Current State & Action (0, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  266\n",
            "Current State & Action (0, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  267\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  268\n",
            "Current State & Action (0, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -1\n",
            "\n",
            "\n",
            "STEP  269\n",
            "Current State & Action (0, 4) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -1\n",
            "\n",
            "\n",
            "STEP  270\n",
            "Current State & Action (0, 4) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -2\n",
            "\n",
            "\n",
            "STEP  271\n",
            "Current State & Action (0, 4) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  272\n",
            "Current State & Action (0, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  273\n",
            "Current State & Action (0, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  274\n",
            "Current State & Action (0, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -1\n",
            "\n",
            "\n",
            "STEP  275\n",
            "Current State & Action (0, 4) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 3) -1\n",
            "\n",
            "\n",
            "STEP  276\n",
            "Current State & Action (0, 3) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 3) -1\n",
            "\n",
            "\n",
            "STEP  277\n",
            "Current State & Action (1, 3) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 2) -1\n",
            "\n",
            "\n",
            "STEP  278\n",
            "Current State & Action (1, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 3) -1\n",
            "\n",
            "\n",
            "STEP  279\n",
            "Current State & Action (1, 3) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 3) -2\n",
            "\n",
            "\n",
            "STEP  280\n",
            "Current State & Action (1, 3) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 3) -2\n",
            "\n",
            "\n",
            "STEP  281\n",
            "Current State & Action (1, 3) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 3) -1\n",
            "\n",
            "\n",
            "STEP  282\n",
            "Current State & Action (0, 3) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  283\n",
            "Current State & Action (0, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  284\n",
            "Current State & Action (0, 2) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 2) -1\n",
            "\n",
            "\n",
            "STEP  285\n",
            "Current State & Action (1, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  286\n",
            "Current State & Action (0, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 3) -1\n",
            "\n",
            "\n",
            "STEP  287\n",
            "Current State & Action (0, 3) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  288\n",
            "Current State & Action (0, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  289\n",
            "Current State & Action (0, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  290\n",
            "Current State & Action (0, 2) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  291\n",
            "Current State & Action (0, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  292\n",
            "Current State & Action (0, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  293\n",
            "Current State & Action (0, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  294\n",
            "Current State & Action (0, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  295\n",
            "Current State & Action (0, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  296\n",
            "Current State & Action (0, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  297\n",
            "Current State & Action (0, 2) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  298\n",
            "Current State & Action (0, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  299\n",
            "Current State & Action (1, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  300\n",
            "Current State & Action (1, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 0) -1\n",
            "\n",
            "\n",
            "STEP  301\n",
            "Current State & Action (2, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 1) -1\n",
            "\n",
            "\n",
            "STEP  302\n",
            "Current State & Action (2, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 1) -1\n",
            "\n",
            "\n",
            "STEP  303\n",
            "Current State & Action (3, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 1) -1\n",
            "\n",
            "\n",
            "STEP  304\n",
            "Current State & Action (2, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  305\n",
            "Current State & Action (1, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  306\n",
            "Current State & Action (0, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  307\n",
            "Current State & Action (0, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  308\n",
            "Current State & Action (0, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  309\n",
            "Current State & Action (0, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  310\n",
            "Current State & Action (0, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  311\n",
            "Current State & Action (0, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  312\n",
            "Current State & Action (0, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  313\n",
            "Current State & Action (0, 0) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  314\n",
            "Current State & Action (0, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  315\n",
            "Current State & Action (1, 0) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  316\n",
            "Current State & Action (1, 0) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  317\n",
            "Current State & Action (1, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  318\n",
            "Current State & Action (1, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 1) -1\n",
            "\n",
            "\n",
            "STEP  319\n",
            "Current State & Action (2, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 0) -1\n",
            "\n",
            "\n",
            "STEP  320\n",
            "Current State & Action (2, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 1) -1\n",
            "\n",
            "\n",
            "STEP  321\n",
            "Current State & Action (2, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 1) -1\n",
            "\n",
            "\n",
            "STEP  322\n",
            "Current State & Action (3, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 1) -1\n",
            "\n",
            "\n",
            "STEP  323\n",
            "Current State & Action (4, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 1) -1\n",
            "\n",
            "\n",
            "STEP  324\n",
            "Current State & Action (3, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 2) -1\n",
            "\n",
            "\n",
            "STEP  325\n",
            "Current State & Action (3, 2) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 2) -1\n",
            "\n",
            "\n",
            "STEP  326\n",
            "Current State & Action (4, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 2) -2\n",
            "\n",
            "\n",
            "STEP  327\n",
            "Current State & Action (4, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 2) -2\n",
            "\n",
            "\n",
            "STEP  328\n",
            "Current State & Action (4, 2) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 2) -1\n",
            "\n",
            "\n",
            "STEP  329\n",
            "Current State & Action (5, 2) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 1) -1\n",
            "\n",
            "\n",
            "STEP  330\n",
            "Current State & Action (5, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 2) -1\n",
            "\n",
            "\n",
            "STEP  331\n",
            "Current State & Action (5, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 2) -1\n",
            "\n",
            "\n",
            "STEP  332\n",
            "Current State & Action (4, 2) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 2) -1\n",
            "\n",
            "\n",
            "STEP  333\n",
            "Current State & Action (5, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 2) -2\n",
            "\n",
            "\n",
            "STEP  334\n",
            "Current State & Action (5, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 2) -2\n",
            "\n",
            "\n",
            "STEP  335\n",
            "Current State & Action (5, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 2) -2\n",
            "\n",
            "\n",
            "STEP  336\n",
            "Current State & Action (5, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 2) -1\n",
            "\n",
            "\n",
            "STEP  337\n",
            "Current State & Action (4, 2) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 1) -1\n",
            "\n",
            "\n",
            "STEP  338\n",
            "Current State & Action (4, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 2) -1\n",
            "\n",
            "\n",
            "STEP  339\n",
            "Current State & Action (4, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 2) -2\n",
            "\n",
            "\n",
            "STEP  340\n",
            "Current State & Action (4, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 2) -2\n",
            "\n",
            "\n",
            "STEP  341\n",
            "Current State & Action (4, 2) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 2) -1\n",
            "\n",
            "\n",
            "STEP  342\n",
            "Current State & Action (5, 2) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 1) -1\n",
            "\n",
            "\n",
            "STEP  343\n",
            "Current State & Action (5, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 1) -1\n",
            "\n",
            "\n",
            "STEP  344\n",
            "Current State & Action (6, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 1) -1\n",
            "\n",
            "\n",
            "STEP  345\n",
            "Current State & Action (7, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 0) -1\n",
            "\n",
            "\n",
            "STEP  346\n",
            "Current State & Action (7, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 0) -1\n",
            "\n",
            "\n",
            "STEP  347\n",
            "Current State & Action (6, 0) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 0) -1\n",
            "\n",
            "\n",
            "STEP  348\n",
            "Current State & Action (6, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 1) -1\n",
            "\n",
            "\n",
            "STEP  349\n",
            "Current State & Action (6, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 1) -1\n",
            "\n",
            "\n",
            "STEP  350\n",
            "Current State & Action (5, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 0) -1\n",
            "\n",
            "\n",
            "STEP  351\n",
            "Current State & Action (5, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 0) -1\n",
            "\n",
            "\n",
            "STEP  352\n",
            "Current State & Action (4, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 0) -1\n",
            "\n",
            "\n",
            "STEP  353\n",
            "Current State & Action (5, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 0) -1\n",
            "\n",
            "\n",
            "STEP  354\n",
            "Current State & Action (4, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 0) -1\n",
            "\n",
            "\n",
            "STEP  355\n",
            "Current State & Action (3, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 0) -1\n",
            "\n",
            "\n",
            "STEP  356\n",
            "Current State & Action (4, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 0) -1\n",
            "\n",
            "\n",
            "STEP  357\n",
            "Current State & Action (3, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 0) -1\n",
            "\n",
            "\n",
            "STEP  358\n",
            "Current State & Action (4, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 1) -1\n",
            "\n",
            "\n",
            "STEP  359\n",
            "Current State & Action (4, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 1) -1\n",
            "\n",
            "\n",
            "STEP  360\n",
            "Current State & Action (3, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 0) -1\n",
            "\n",
            "\n",
            "STEP  361\n",
            "Current State & Action (3, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 0) -1\n",
            "\n",
            "\n",
            "STEP  362\n",
            "Current State & Action (4, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 0) -1\n",
            "\n",
            "\n",
            "STEP  363\n",
            "Current State & Action (5, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 0) -1\n",
            "\n",
            "\n",
            "STEP  364\n",
            "Current State & Action (6, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 0) -1\n",
            "\n",
            "\n",
            "STEP  365\n",
            "Current State & Action (5, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 0) -1\n",
            "\n",
            "\n",
            "STEP  366\n",
            "Current State & Action (6, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 1) -1\n",
            "\n",
            "\n",
            "STEP  367\n",
            "Current State & Action (6, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 1) -1\n",
            "\n",
            "\n",
            "STEP  368\n",
            "Current State & Action (5, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 1) -1\n",
            "\n",
            "\n",
            "STEP  369\n",
            "Current State & Action (4, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 2) -1\n",
            "\n",
            "\n",
            "STEP  370\n",
            "Current State & Action (4, 2) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 2) -1\n",
            "\n",
            "\n",
            "STEP  371\n",
            "Current State & Action (5, 2) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 1) -1\n",
            "\n",
            "\n",
            "STEP  372\n",
            "Current State & Action (5, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 0) -1\n",
            "\n",
            "\n",
            "STEP  373\n",
            "Current State & Action (5, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 0) -1\n",
            "\n",
            "\n",
            "STEP  374\n",
            "Current State & Action (4, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 1) -1\n",
            "\n",
            "\n",
            "STEP  375\n",
            "Current State & Action (4, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 1) -1\n",
            "\n",
            "\n",
            "STEP  376\n",
            "Current State & Action (3, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 1) -1\n",
            "\n",
            "\n",
            "STEP  377\n",
            "Current State & Action (4, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 0) -1\n",
            "\n",
            "\n",
            "STEP  378\n",
            "Current State & Action (4, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 1) -1\n",
            "\n",
            "\n",
            "STEP  379\n",
            "Current State & Action (4, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 2) -1\n",
            "\n",
            "\n",
            "STEP  380\n",
            "Current State & Action (4, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 2) -1\n",
            "\n",
            "\n",
            "STEP  381\n",
            "Current State & Action (3, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 3) -1\n",
            "\n",
            "\n",
            "STEP  382\n",
            "Current State & Action (3, 3) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 3) -10\n",
            "\n",
            "\n",
            "TERMINAL\n",
            "Episode 96\n",
            "Terminal? ...  False\n",
            "\n",
            "\n",
            "STEP  0\n",
            "Current State & Action (0, 0) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  1\n",
            "Current State & Action (0, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  2\n",
            "Current State & Action (0, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  3\n",
            "Current State & Action (0, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  4\n",
            "Current State & Action (0, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  5\n",
            "Current State & Action (0, 2) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  6\n",
            "Current State & Action (0, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  7\n",
            "Current State & Action (0, 0) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  8\n",
            "Current State & Action (0, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  9\n",
            "Current State & Action (0, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  10\n",
            "Current State & Action (1, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  11\n",
            "Current State & Action (0, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  12\n",
            "Current State & Action (1, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  13\n",
            "Current State & Action (0, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  14\n",
            "Current State & Action (0, 2) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  15\n",
            "Current State & Action (0, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  16\n",
            "Current State & Action (0, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  17\n",
            "Current State & Action (0, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  18\n",
            "Current State & Action (0, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  19\n",
            "Current State & Action (0, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  20\n",
            "Current State & Action (1, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  21\n",
            "Current State & Action (1, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  22\n",
            "Current State & Action (0, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  23\n",
            "Current State & Action (0, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  24\n",
            "Current State & Action (1, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  25\n",
            "Current State & Action (0, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  26\n",
            "Current State & Action (0, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  27\n",
            "Current State & Action (0, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  28\n",
            "Current State & Action (0, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  29\n",
            "Current State & Action (0, 0) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  30\n",
            "Current State & Action (0, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  31\n",
            "Current State & Action (1, 0) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  32\n",
            "Current State & Action (1, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 0) -1\n",
            "\n",
            "\n",
            "STEP  33\n",
            "Current State & Action (2, 0) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 0) -1\n",
            "\n",
            "\n",
            "STEP  34\n",
            "Current State & Action (2, 0) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 0) -1\n",
            "\n",
            "\n",
            "STEP  35\n",
            "Current State & Action (2, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  36\n",
            "Current State & Action (1, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  37\n",
            "Current State & Action (1, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 1) -1\n",
            "\n",
            "\n",
            "STEP  38\n",
            "Current State & Action (2, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 0) -1\n",
            "\n",
            "\n",
            "STEP  39\n",
            "Current State & Action (2, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 1) -1\n",
            "\n",
            "\n",
            "STEP  40\n",
            "Current State & Action (2, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  41\n",
            "Current State & Action (1, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 1) -1\n",
            "\n",
            "\n",
            "STEP  42\n",
            "Current State & Action (2, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 1) -1\n",
            "\n",
            "\n",
            "STEP  43\n",
            "Current State & Action (3, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 1) -1\n",
            "\n",
            "\n",
            "STEP  44\n",
            "Current State & Action (4, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 1) -1\n",
            "\n",
            "\n",
            "STEP  45\n",
            "Current State & Action (5, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 2) -1\n",
            "\n",
            "\n",
            "STEP  46\n",
            "Current State & Action (5, 2) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 2) -1\n",
            "\n",
            "\n",
            "STEP  47\n",
            "Current State & Action (6, 2) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 1) -1\n",
            "\n",
            "\n",
            "STEP  48\n",
            "Current State & Action (6, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 1) -1\n",
            "\n",
            "\n",
            "STEP  49\n",
            "Current State & Action (7, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 1) -1\n",
            "\n",
            "\n",
            "STEP  50\n",
            "Current State & Action (8, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 2) -1\n",
            "\n",
            "\n",
            "STEP  51\n",
            "Current State & Action (8, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 2) -1\n",
            "\n",
            "\n",
            "STEP  52\n",
            "Current State & Action (7, 2) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 2) -1\n",
            "\n",
            "\n",
            "STEP  53\n",
            "Current State & Action (8, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 3) -1\n",
            "\n",
            "\n",
            "STEP  54\n",
            "Current State & Action (8, 3) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 4) -1\n",
            "\n",
            "\n",
            "STEP  55\n",
            "Current State & Action (8, 4) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 5) -1\n",
            "\n",
            "\n",
            "STEP  56\n",
            "Current State & Action (8, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  57\n",
            "Current State & Action (8, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  58\n",
            "Current State & Action (8, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  59\n",
            "Current State & Action (8, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  60\n",
            "Current State & Action (8, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  61\n",
            "Current State & Action (8, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 5) -1\n",
            "\n",
            "\n",
            "STEP  62\n",
            "Current State & Action (8, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  63\n",
            "Current State & Action (8, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  64\n",
            "Current State & Action (8, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  65\n",
            "Current State & Action (7, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  66\n",
            "Current State & Action (8, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  67\n",
            "Current State & Action (7, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  68\n",
            "Current State & Action (7, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  69\n",
            "Current State & Action (7, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  70\n",
            "Current State & Action (6, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  71\n",
            "Current State & Action (6, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  72\n",
            "Current State & Action (7, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  73\n",
            "Current State & Action (6, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  74\n",
            "Current State & Action (7, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  75\n",
            "Current State & Action (8, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 5) -1\n",
            "\n",
            "\n",
            "STEP  76\n",
            "Current State & Action (8, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -1\n",
            "\n",
            "\n",
            "STEP  77\n",
            "Current State & Action (7, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  78\n",
            "Current State & Action (7, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 6) -1\n",
            "\n",
            "\n",
            "STEP  79\n",
            "Current State & Action (6, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 6) -1\n",
            "\n",
            "\n",
            "STEP  80\n",
            "Current State & Action (5, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 7) -1\n",
            "\n",
            "\n",
            "STEP  81\n",
            "Current State & Action (5, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 6) -1\n",
            "\n",
            "\n",
            "STEP  82\n",
            "Current State & Action (5, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 5) -1\n",
            "\n",
            "\n",
            "STEP  83\n",
            "Current State & Action (5, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 5) -10\n",
            "\n",
            "\n",
            "TERMINAL\n",
            "Episode 97\n",
            "Terminal? ...  False\n",
            "\n",
            "\n",
            "STEP  0\n",
            "Current State & Action (8, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  1\n",
            "Current State & Action (8, 8) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 8) -1\n",
            "\n",
            "\n",
            "STEP  2\n",
            "Current State & Action (8, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  3\n",
            "Current State & Action (8, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  4\n",
            "Current State & Action (7, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  5\n",
            "Current State & Action (7, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  6\n",
            "Current State & Action (7, 7) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  7\n",
            "Current State & Action (7, 8) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 8) -1\n",
            "\n",
            "\n",
            "STEP  8\n",
            "Current State & Action (7, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  9\n",
            "Current State & Action (7, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 7) -1\n",
            "\n",
            "\n",
            "STEP  10\n",
            "Current State & Action (6, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  11\n",
            "Current State & Action (7, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  12\n",
            "Current State & Action (7, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  13\n",
            "Current State & Action (7, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  14\n",
            "Current State & Action (7, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  15\n",
            "Current State & Action (7, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  16\n",
            "Current State & Action (8, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  17\n",
            "Current State & Action (8, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 6) -1\n",
            "\n",
            "\n",
            "STEP  18\n",
            "Current State & Action (8, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 5) -1\n",
            "\n",
            "\n",
            "STEP  19\n",
            "Current State & Action (8, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -1\n",
            "\n",
            "\n",
            "STEP  20\n",
            "Current State & Action (7, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -2\n",
            "\n",
            "\n",
            "STEP  21\n",
            "Current State & Action (7, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -2\n",
            "\n",
            "\n",
            "STEP  22\n",
            "Current State & Action (7, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -2\n",
            "\n",
            "\n",
            "STEP  23\n",
            "Current State & Action (7, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 5) -1\n",
            "\n",
            "\n",
            "STEP  24\n",
            "Current State & Action (6, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -1\n",
            "\n",
            "\n",
            "STEP  25\n",
            "Current State & Action (7, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  26\n",
            "Current State & Action (7, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  27\n",
            "Current State & Action (7, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (8, 7) -1\n",
            "\n",
            "\n",
            "STEP  28\n",
            "Current State & Action (8, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 7) -1\n",
            "\n",
            "\n",
            "STEP  29\n",
            "Current State & Action (7, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 6) -1\n",
            "\n",
            "\n",
            "STEP  30\n",
            "Current State & Action (7, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (7, 5) -1\n",
            "\n",
            "\n",
            "STEP  31\n",
            "Current State & Action (7, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (6, 5) -1\n",
            "\n",
            "\n",
            "STEP  32\n",
            "Current State & Action (6, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 5) -1\n",
            "\n",
            "\n",
            "STEP  33\n",
            "Current State & Action (5, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (5, 5) -10\n",
            "\n",
            "\n",
            "TERMINAL\n",
            "Episode 98\n",
            "Terminal? ...  False\n",
            "\n",
            "\n",
            "STEP  0\n",
            "Current State & Action (0, 8) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  1\n",
            "Current State & Action (0, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  2\n",
            "Current State & Action (0, 7) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 7) -1\n",
            "\n",
            "\n",
            "STEP  3\n",
            "Current State & Action (0, 7) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 7) -1\n",
            "\n",
            "\n",
            "STEP  4\n",
            "Current State & Action (1, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  5\n",
            "Current State & Action (1, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -1\n",
            "\n",
            "\n",
            "STEP  6\n",
            "Current State & Action (2, 6) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 7) -1\n",
            "\n",
            "\n",
            "STEP  7\n",
            "Current State & Action (2, 7) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 6) -1\n",
            "\n",
            "\n",
            "STEP  8\n",
            "Current State & Action (2, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  9\n",
            "Current State & Action (1, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  10\n",
            "Current State & Action (0, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  11\n",
            "Current State & Action (0, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  12\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  13\n",
            "Current State & Action (0, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  14\n",
            "Current State & Action (0, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  15\n",
            "Current State & Action (0, 6) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -1\n",
            "\n",
            "\n",
            "STEP  16\n",
            "Current State & Action (1, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 6) -2\n",
            "\n",
            "\n",
            "STEP  17\n",
            "Current State & Action (1, 6) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  18\n",
            "Current State & Action (0, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  19\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  20\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  21\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  22\n",
            "Current State & Action (0, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  23\n",
            "Current State & Action (0, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  24\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  25\n",
            "Current State & Action (0, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  26\n",
            "Current State & Action (0, 5) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  27\n",
            "Current State & Action (0, 5) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 6) -1\n",
            "\n",
            "\n",
            "STEP  28\n",
            "Current State & Action (0, 6) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  29\n",
            "Current State & Action (0, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -1\n",
            "\n",
            "\n",
            "STEP  30\n",
            "Current State & Action (0, 4) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -1\n",
            "\n",
            "\n",
            "STEP  31\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  32\n",
            "Current State & Action (0, 5) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 5) -2\n",
            "\n",
            "\n",
            "STEP  33\n",
            "Current State & Action (0, 5) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -1\n",
            "\n",
            "\n",
            "STEP  34\n",
            "Current State & Action (0, 4) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 4) -1\n",
            "\n",
            "\n",
            "STEP  35\n",
            "Current State & Action (0, 4) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 3) -1\n",
            "\n",
            "\n",
            "STEP  36\n",
            "Current State & Action (0, 3) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  37\n",
            "Current State & Action (0, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  38\n",
            "Current State & Action (0, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 3) -1\n",
            "\n",
            "\n",
            "STEP  39\n",
            "Current State & Action (0, 3) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  40\n",
            "Current State & Action (0, 2) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  41\n",
            "Current State & Action (0, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  42\n",
            "Current State & Action (0, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  43\n",
            "Current State & Action (0, 2) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  44\n",
            "Current State & Action (0, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  45\n",
            "Current State & Action (0, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  46\n",
            "Current State & Action (0, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 2) -1\n",
            "\n",
            "\n",
            "STEP  47\n",
            "Current State & Action (0, 2) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  48\n",
            "Current State & Action (0, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  49\n",
            "Current State & Action (0, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  50\n",
            "Current State & Action (1, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 0) -1\n",
            "\n",
            "\n",
            "STEP  51\n",
            "Current State & Action (2, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  52\n",
            "Current State & Action (1, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  53\n",
            "Current State & Action (1, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  54\n",
            "Current State & Action (0, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  55\n",
            "Current State & Action (0, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  56\n",
            "Current State & Action (1, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  57\n",
            "Current State & Action (1, 0) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  58\n",
            "Current State & Action (1, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  59\n",
            "Current State & Action (1, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  60\n",
            "Current State & Action (0, 1) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  61\n",
            "Current State & Action (1, 1) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  62\n",
            "Current State & Action (0, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  63\n",
            "Current State & Action (0, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 1) -1\n",
            "\n",
            "\n",
            "STEP  64\n",
            "Current State & Action (0, 1) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  65\n",
            "Current State & Action (0, 0) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  66\n",
            "Current State & Action (0, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  67\n",
            "Current State & Action (1, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  68\n",
            "Current State & Action (1, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 2) -1\n",
            "\n",
            "\n",
            "STEP  69\n",
            "Current State & Action (1, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 3) -1\n",
            "\n",
            "\n",
            "STEP  70\n",
            "Current State & Action (1, 3) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 3) -1\n",
            "\n",
            "\n",
            "STEP  71\n",
            "Current State & Action (2, 3) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 4) -1\n",
            "\n",
            "\n",
            "STEP  72\n",
            "Current State & Action (2, 4) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 3) -1\n",
            "\n",
            "\n",
            "STEP  73\n",
            "Current State & Action (2, 3) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 3) -1\n",
            "\n",
            "\n",
            "STEP  74\n",
            "Current State & Action (1, 3) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 2) -1\n",
            "\n",
            "\n",
            "STEP  75\n",
            "Current State & Action (1, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 3) -1\n",
            "\n",
            "\n",
            "STEP  76\n",
            "Current State & Action (1, 3) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 3) -2\n",
            "\n",
            "\n",
            "STEP  77\n",
            "Current State & Action (1, 3) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 3) -1\n",
            "\n",
            "\n",
            "STEP  78\n",
            "Current State & Action (2, 3) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 4) -1\n",
            "\n",
            "\n",
            "STEP  79\n",
            "Current State & Action (2, 4) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 3) -1\n",
            "\n",
            "\n",
            "STEP  80\n",
            "Current State & Action (2, 3) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 3) -1\n",
            "\n",
            "\n",
            "STEP  81\n",
            "Current State & Action (3, 3) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 3) -10\n",
            "\n",
            "\n",
            "TERMINAL\n",
            "Episode 99\n",
            "Terminal? ...  False\n",
            "\n",
            "\n",
            "STEP  0\n",
            "Current State & Action (0, 0) [0, -1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (0, 0) -1\n",
            "\n",
            "\n",
            "STEP  1\n",
            "Current State & Action (0, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  2\n",
            "Current State & Action (1, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 0) -1\n",
            "\n",
            "\n",
            "STEP  3\n",
            "Current State & Action (2, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  4\n",
            "Current State & Action (1, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 0) -1\n",
            "\n",
            "\n",
            "STEP  5\n",
            "Current State & Action (2, 0) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 0) -1\n",
            "\n",
            "\n",
            "STEP  6\n",
            "Current State & Action (3, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 0) -1\n",
            "\n",
            "\n",
            "STEP  7\n",
            "Current State & Action (2, 0) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 0) -1\n",
            "\n",
            "\n",
            "STEP  8\n",
            "Current State & Action (1, 0) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 1) -1\n",
            "\n",
            "\n",
            "STEP  9\n",
            "Current State & Action (1, 1) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 2) -1\n",
            "\n",
            "\n",
            "STEP  10\n",
            "Current State & Action (1, 2) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 2) -1\n",
            "\n",
            "\n",
            "STEP  11\n",
            "Current State & Action (2, 2) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (1, 2) -1\n",
            "\n",
            "\n",
            "STEP  12\n",
            "Current State & Action (1, 2) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 2) -1\n",
            "\n",
            "\n",
            "STEP  13\n",
            "Current State & Action (2, 2) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 3) -1\n",
            "\n",
            "\n",
            "STEP  14\n",
            "Current State & Action (2, 3) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 4) -1\n",
            "\n",
            "\n",
            "STEP  15\n",
            "Current State & Action (2, 4) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 4) -2\n",
            "\n",
            "\n",
            "STEP  16\n",
            "Current State & Action (2, 4) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 4) -1\n",
            "\n",
            "\n",
            "STEP  17\n",
            "Current State & Action (3, 4) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 4) -2\n",
            "\n",
            "\n",
            "STEP  18\n",
            "Current State & Action (3, 4) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 4) -2\n",
            "\n",
            "\n",
            "STEP  19\n",
            "Current State & Action (3, 4) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 4) -2\n",
            "\n",
            "\n",
            "STEP  20\n",
            "Current State & Action (3, 4) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 4) -1\n",
            "\n",
            "\n",
            "STEP  21\n",
            "Current State & Action (2, 4) [-1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 4) -2\n",
            "\n",
            "\n",
            "STEP  22\n",
            "Current State & Action (2, 4) [0, 1]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (2, 4) -2\n",
            "\n",
            "\n",
            "STEP  23\n",
            "Current State & Action (2, 4) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (3, 4) -1\n",
            "\n",
            "\n",
            "STEP  24\n",
            "Current State & Action (3, 4) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 4) -1\n",
            "\n",
            "\n",
            "STEP  25\n",
            "Current State & Action (4, 4) [1, 0]\n",
            "Taking step with Action A...\n",
            "New State & Reward:  (4, 4) 10\n",
            "\n",
            "\n",
            "TERMINAL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rQF_D3ymqHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2315e9cb-e344-4ac3-abad-7633545ac708"
      },
      "source": [
        "# lets test an episode\n",
        "game = MazeGrid(9)\n",
        "print('current_state: ', game.current_state)\n",
        "episode = game.MC_episode(1)\n",
        "state_actions_pairs = [(s, a) for (s, a, r) in episode]\n",
        "state_actions_pairs"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current_state:  (0, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((0, 8), 0),\n",
              " ((0, 8), 1),\n",
              " ((1, 8), 2),\n",
              " ((1, 7), 2),\n",
              " ((1, 6), 1),\n",
              " ((2, 6), 3),\n",
              " ((2, 7), 1),\n",
              " ((3, 7), 3),\n",
              " ((3, 8), 0),\n",
              " ((2, 8), 1),\n",
              " ((3, 8), 2),\n",
              " ((3, 7), 2),\n",
              " ((3, 6), 1),\n",
              " ((4, 6), 3),\n",
              " ((4, 7), 0),\n",
              " ((3, 7), 2),\n",
              " ((3, 6), 3),\n",
              " ((3, 7), 3),\n",
              " ((3, 8), 0),\n",
              " ((2, 8), 3),\n",
              " ((2, 8), 1),\n",
              " ((3, 8), 3),\n",
              " ((3, 8), 0),\n",
              " ((2, 8), 1),\n",
              " ((3, 8), 1),\n",
              " ((4, 8), 1),\n",
              " ((5, 8), 0),\n",
              " ((4, 8), 3),\n",
              " ((4, 8), 2),\n",
              " ((4, 7), 0),\n",
              " ((3, 7), 1),\n",
              " ((4, 7), 2),\n",
              " ((4, 6), 0),\n",
              " ((3, 6), 1),\n",
              " ((4, 6), 0),\n",
              " ((3, 6), 3),\n",
              " ((3, 7), 3),\n",
              " ((3, 8), 1),\n",
              " ((4, 8), 0),\n",
              " ((3, 8), 0),\n",
              " ((2, 8), 3),\n",
              " ((2, 8), 3),\n",
              " ((2, 8), 2),\n",
              " ((2, 7), 0),\n",
              " ((1, 7), 3),\n",
              " ((1, 8), 2),\n",
              " ((1, 7), 1),\n",
              " ((2, 7), 3),\n",
              " ((2, 8), 2),\n",
              " ((2, 7), 3),\n",
              " ((2, 8), 3),\n",
              " ((2, 8), 0),\n",
              " ((1, 8), 3),\n",
              " ((1, 8), 3),\n",
              " ((1, 8), 2),\n",
              " ((1, 7), 1),\n",
              " ((2, 7), 0),\n",
              " ((1, 7), 1),\n",
              " ((2, 7), 0),\n",
              " ((1, 7), 2),\n",
              " ((1, 6), 3),\n",
              " ((1, 7), 1),\n",
              " ((2, 7), 2),\n",
              " ((2, 6), 0),\n",
              " ((1, 6), 1),\n",
              " ((2, 6), 1),\n",
              " ((3, 6), 2),\n",
              " ((3, 6), 3),\n",
              " ((3, 7), 1),\n",
              " ((4, 7), 2),\n",
              " ((4, 6), 3),\n",
              " ((4, 7), 1),\n",
              " ((5, 7), 0),\n",
              " ((4, 7), 2),\n",
              " ((4, 6), 3),\n",
              " ((4, 7), 3),\n",
              " ((4, 8), 0),\n",
              " ((3, 8), 2),\n",
              " ((3, 7), 1),\n",
              " ((4, 7), 1),\n",
              " ((5, 7), 3),\n",
              " ((5, 8), 0),\n",
              " ((4, 8), 2),\n",
              " ((4, 7), 2),\n",
              " ((4, 6), 2),\n",
              " ((4, 6), 0),\n",
              " ((3, 6), 3),\n",
              " ((3, 7), 3),\n",
              " ((3, 8), 3),\n",
              " ((3, 8), 2),\n",
              " ((3, 7), 0),\n",
              " ((2, 7), 3),\n",
              " ((2, 8), 0),\n",
              " ((1, 8), 3),\n",
              " ((1, 8), 1),\n",
              " ((2, 8), 3),\n",
              " ((2, 8), 2),\n",
              " ((2, 7), 0),\n",
              " ((1, 7), 2),\n",
              " ((1, 6), 1),\n",
              " ((2, 6), 3),\n",
              " ((2, 7), 3),\n",
              " ((2, 8), 0),\n",
              " ((1, 8), 0),\n",
              " ((0, 8), 2),\n",
              " ((0, 7), 1),\n",
              " ((1, 7), 0),\n",
              " ((0, 7), 3),\n",
              " ((0, 8), 3),\n",
              " ((0, 8), 1),\n",
              " ((1, 8), 3),\n",
              " ((1, 8), 2),\n",
              " ((1, 7), 3),\n",
              " ((1, 8), 0),\n",
              " ((0, 8), 0),\n",
              " ((0, 8), 1),\n",
              " ((1, 8), 0),\n",
              " ((0, 8), 3),\n",
              " ((0, 8), 1),\n",
              " ((1, 8), 3),\n",
              " ((1, 8), 1),\n",
              " ((2, 8), 3),\n",
              " ((2, 8), 0),\n",
              " ((1, 8), 2),\n",
              " ((1, 7), 0),\n",
              " ((0, 7), 0),\n",
              " ((0, 7), 1),\n",
              " ((1, 7), 0),\n",
              " ((0, 7), 3),\n",
              " ((0, 8), 1),\n",
              " ((1, 8), 2),\n",
              " ((1, 7), 0),\n",
              " ((0, 7), 3),\n",
              " ((0, 8), 3),\n",
              " ((0, 8), 0),\n",
              " ((0, 8), 2),\n",
              " ((0, 7), 1),\n",
              " ((1, 7), 0),\n",
              " ((0, 7), 2),\n",
              " ((0, 6), 1),\n",
              " ((1, 6), 3),\n",
              " ((1, 7), 2),\n",
              " ((1, 6), 1),\n",
              " ((2, 6), 2),\n",
              " ((2, 6), 3),\n",
              " ((2, 7), 1),\n",
              " ((3, 7), 3),\n",
              " ((3, 8), 2),\n",
              " ((3, 7), 1),\n",
              " ((4, 7), 3),\n",
              " ((4, 8), 1),\n",
              " ((5, 8), 0),\n",
              " ((4, 8), 3),\n",
              " ((4, 8), 1),\n",
              " ((5, 8), 1),\n",
              " ((6, 8), 2),\n",
              " ((6, 7), 2),\n",
              " ((6, 6), 1),\n",
              " ((7, 6), 0),\n",
              " ((6, 6), 3),\n",
              " ((6, 7), 1),\n",
              " ((7, 7), 2),\n",
              " ((7, 6), 0),\n",
              " ((6, 6), 3),\n",
              " ((6, 7), 3),\n",
              " ((6, 8), 0),\n",
              " ((5, 8), 0),\n",
              " ((4, 8), 1),\n",
              " ((5, 8), 1),\n",
              " ((6, 8), 0),\n",
              " ((5, 8), 2),\n",
              " ((5, 7), 3),\n",
              " ((5, 8), 2),\n",
              " ((5, 7), 2),\n",
              " ((5, 6), 2),\n",
              " ((5, 5), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}